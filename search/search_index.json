{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"openEO by TiTiler","text":"<p>TiTiler backend for openEO</p> <p></p>"},{"location":"#overview","title":"Overview","text":"<p>openEO by TiTiler is a TiTiler backend implementation for openEO developed by  and .</p> <p>The main goal of this project is to provide a light and fast backend for openEO services and processes using the TiTiler engine. This simplicity comes with some specific implementation choices like the type of data managed by the backend. It is focused on image raster data that can be processed on-the-fly and served as tiles or as light dynamic raw data. For more details about the implementation choices, see the Concepts section.</p> <p>The application implements the openEO API (L1A and L1C) profiles.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>STAC API integration with external STAC services</li> <li>Synchronous processing capabilities</li> <li>Various output formats (e.g., JPEG, PNG)</li> <li>Multiple supported processes</li> <li>Dynamic tiling services</li> <li>FastAPI-based application</li> <li>Middleware for CORS, compression, and caching</li> <li>Optimized RasterStack data model for consistent processing</li> <li>LazyRasterStack implementation for improved performance</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>For installation and setup instructions, see: - Local Setup for development environment - Kubernetes Guide for production deployment - Administrator Guide for configuration options</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Project: Overview and release notes</li> <li>Architecture: Core concepts and data models</li> <li>Deployment: Installation and configuration guides</li> <li>Development: Contributing guidelines</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License.</p>"},{"location":"#authors","title":"Authors","text":"<p>Created by Development Seed and Sinergise.</p> <p>See contributors for a listing of individual contributors.</p>"},{"location":"admin-guide/","title":"Administrator Guide","text":"<p>This guide provides information for system administrators managing an openEO by TiTiler deployment. The implementation details can be found in the codebase, particularly in <code>titiler/openeo/settings.py</code> for configuration options.</p>"},{"location":"admin-guide/#system-requirements","title":"System Requirements","text":""},{"location":"admin-guide/#environment-variables","title":"Environment Variables","text":"<p>openEO by TiTiler is configured through environment variables. Key configuration areas include:</p>"},{"location":"admin-guide/#api-settings-apisettings","title":"API Settings (<code>ApiSettings</code>)","text":"<pre><code>TITILER_OPENEO_API_NAME=\"openEO by TiTiler\"\nTITILER_OPENEO_API_CORS_ORIGINS=\"*\"\nTITILER_OPENEO_API_CORS_ALLOW_METHODS=\"GET,POST,PUT,PATCH,DELETE,OPTIONS\"\nTITILER_OPENEO_API_ROOT_PATH=\"\"\nTITILER_OPENEO_API_DEBUG=false\n</code></pre>"},{"location":"admin-guide/#backend-settings-backendsettings","title":"Backend Settings (<code>BackendSettings</code>)","text":"<pre><code>TITILER_OPENEO_STAC_API_URL=\"https://your-stac-api\"\nTITILER_OPENEO_SERVICE_STORE_URL=\"path-to-services-config\"\nTITILER_OPENEO_TILE_STORE_URL=\"optional-tile-store-url\"\n</code></pre>"},{"location":"admin-guide/#processing-settings-processingsettings","title":"Processing Settings (<code>ProcessingSettings</code>)","text":"<pre><code>TITILER_OPENEO_PROCESSING_MAX_PIXELS=100000000\nTITILER_OPENEO_PROCESSING_MAX_ITEMS=20\n</code></pre>"},{"location":"admin-guide/#cache-settings-cachesettings","title":"Cache Settings (<code>CacheSettings</code>)","text":"<pre><code>TITILER_OPENEO_CACHE_TTL=300\nTITILER_OPENEO_CACHE_MAXSIZE=512\nTITILER_OPENEO_CACHE_DISABLE=false\n</code></pre>"},{"location":"admin-guide/#authentication","title":"Authentication","text":"<p>openEO by TiTiler supports two authentication methods:</p> <ol> <li>Basic Authentication (default)</li> <li>Configured through <code>AuthSettings</code></li> <li>Set <code>TITILER_OPENEO_AUTH_METHOD=basic</code></li> <li> <p>Configure users in environment:      <pre><code>TITILER_OPENEO_AUTH_USERS='{\"user1\": {\"password\": \"pass1\", \"roles\": [\"user\"]}}'\n</code></pre></p> </li> <li> <p>OpenID Connect</p> </li> <li>See OpenID Connect Configuration for details</li> </ol>"},{"location":"admin-guide/#performance-tuning","title":"Performance Tuning","text":""},{"location":"admin-guide/#cache-configuration","title":"Cache Configuration","text":"<p>The caching system can be tuned through the following settings: - <code>TITILER_OPENEO_CACHE_TTL</code>: Time-to-live for cached items (seconds) - <code>TITILER_OPENEO_CACHE_MAXSIZE</code>: Maximum number of items in cache - <code>TITILER_OPENEO_CACHE_DISABLE</code>: Disable caching entirely</p>"},{"location":"admin-guide/#processing-limits","title":"Processing Limits","text":"<p>To prevent resource exhaustion: - <code>TITILER_OPENEO_PROCESSING_MAX_PIXELS</code>: Maximum allowed pixels for image processing - <code>TITILER_OPENEO_PROCESSING_MAX_ITEMS</code>: Maximum number of items (STAC items from a API search) in a request</p>"},{"location":"admin-guide/#monitoring","title":"Monitoring","text":""},{"location":"admin-guide/#api-endpoints","title":"API Endpoints","text":"<p>The application provides several endpoints for monitoring:</p> <ul> <li><code>/health</code>: Health check endpoint</li> <li><code>/docs</code>: OpenAPI documentation</li> <li><code>/redoc</code>: Alternative API documentation</li> </ul>"},{"location":"admin-guide/#logging","title":"Logging","text":"<p>Logging configuration is managed through <code>log_config.yaml</code>. The default configuration includes: - Console output - JSON formatting - Different log levels for different components</p>"},{"location":"admin-guide/#security","title":"Security","text":""},{"location":"admin-guide/#cors-configuration","title":"CORS Configuration","text":"<p>Configure CORS settings through: <pre><code>TITILER_OPENEO_API_CORS_ORIGINS=\"domain1.com,domain2.com\"\nTITILER_OPENEO_API_CORS_ALLOW_METHODS=\"GET,POST,PUT,PATCH,DELETE,OPTIONS\"\n</code></pre></p>"},{"location":"admin-guide/#cache-control","title":"Cache Control","text":"<p>Configure cache control headers: <pre><code>TITILER_OPENEO_API_CACHE_STATIC=\"public, max-age=3600\"\nTITILER_OPENEO_API_CACHE_DYNAMIC=\"no-cache\"\nTITILER_OPENEO_API_CACHE_DEFAULT=\"no-store\"\n</code></pre></p>"},{"location":"admin-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"admin-guide/#common-issues","title":"Common Issues","text":"<ol> <li>Authentication Failures</li> <li>Check authentication method configuration</li> <li>Verify user credentials or OIDC settings</li> <li> <p>Check token format and expiration</p> </li> <li> <p>Performance Issues</p> </li> <li>Review cache settings</li> <li>Check processing limits</li> <li> <p>Monitor system resources</p> </li> <li> <p>CORS Issues</p> </li> <li>Verify CORS origins configuration</li> <li>Check allowed methods</li> <li>Review client requests</li> </ol>"},{"location":"admin-guide/#debug-mode","title":"Debug Mode","text":"<p>Enable debug mode for detailed logging: <pre><code>TITILER_OPENEO_API_DEBUG=true\n</code></pre></p>"},{"location":"admin-guide/#maintenance","title":"Maintenance","text":""},{"location":"admin-guide/#backup-considerations","title":"Backup Considerations","text":"<ol> <li>Configuration</li> <li>Environment variables</li> <li>Service configurations</li> <li> <p>Authentication settings</p> </li> <li> <p>Data</p> </li> <li>Tile store data if used</li> <li>Cache contents if persistent</li> </ol>"},{"location":"admin-guide/#updates","title":"Updates","text":"<p>When updating openEO by TiTiler: 1. Review the changelog 2. Backup configuration 3. Test in a staging environment 4. Plan for downtime if needed 5. Update the application 6. Verify functionality</p> <p>For implementation details, refer to the source code.</p>"},{"location":"authorization/","title":"Service Authorization","text":"<p>TiTiler OpenEO implements a flexible service authorization mechanism that controls access to services based on their configuration. Each service can be configured with different access levels through the <code>scope</code> parameter.</p>"},{"location":"authorization/#scopes","title":"Scopes","text":"<p>Services can be configured with one of three scopes:</p> <ul> <li><code>private</code>: Only the service owner can access the service</li> <li><code>restricted</code>: Any authenticated user can access, with optional user-specific restrictions</li> <li><code>public</code> (default): No authentication required, anyone can access the service</li> </ul>"},{"location":"authorization/#configuration","title":"Configuration","text":"<p>Authorization is configured through the service configuration object when creating or updating a service:</p> <pre><code>{\n  \"configuration\": {\n    \"scope\": \"restricted\",\n    \"authorized_users\": [\"user1\", \"user2\"]  // Optional: specific users for restricted scope\n  }\n}\n</code></pre>"},{"location":"authorization/#configuration-parameters","title":"Configuration Parameters","text":"Parameter Type Description <code>scope</code> string Access scope: <code>private</code>, <code>restricted</code>, or <code>public</code> <code>authorized_users</code> array Optional list of user IDs allowed to access a restricted service <code>inject_user</code> boolean Whether to inject the authenticated user as a named parameter '_openeo_user' into the process graph (default: false)."},{"location":"authorization/#implementation","title":"Implementation","text":"<p>The authorization mechanism is implemented in two main components:</p> <ol> <li><code>ServiceAuthorizationManager</code> class (<code>titiler/openeo/services/auth.py</code>):</li> <li>Encapsulates authorization logic</li> <li>Validates access based on service configuration and user context</li> <li> <p>Throws appropriate HTTP exceptions for unauthorized access</p> </li> <li> <p>Service endpoints:</p> </li> <li>Retrieve service configuration</li> <li>Use ServiceAuthorizationManager to enforce access control</li> <li>Pass authorized requests to the service implementation</li> </ol>"},{"location":"authorization/#example-usage","title":"Example Usage","text":"<p>For example:</p> <pre><code>{\n  \"configuration\": {\n    \"scope\": \"restricted\",\n    \"authorized_users\": [\"user1\", \"user2\"],\n    \"inject_user\": true  // Enable user injection into process graph\n  }\n}\n</code></pre> <p>The behavior of the injected user parameter depends on how it's defined in the process's JSON schema:</p> <ol> <li> <p>When the parameter schema defines <code>\"type\": \"string\"</code>: <pre><code>{\n  \"parameters\": {\n    \"user_id\": {\n      \"type\": \"string\",\n      \"description\": \"User identifier\"\n    }\n  }\n}\n</code></pre> The process will receive just the user ID string, even when using from_parameter: <pre><code>{\n  \"process_graph\": {\n    \"example1\": {\n      \"process_id\": \"example_process\",\n      \"arguments\": {\n        \"user_id\": {\n          \"from_parameter\": \"_openeo_user\"  // Will extract just the user_id\n        }\n      }\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>When the parameter schema defines a User object type: <pre><code>{\n  \"parameters\": {\n    \"user\": {\n      \"type\": \"object\",\n      \"description\": \"User object with full properties\"\n    }\n  }\n}\n</code></pre> The process will receive the complete User object: <pre><code>{\n  \"process_graph\": {\n    \"example1\": {\n      \"process_id\": \"example_process\",\n      \"arguments\": {\n        \"user\": {\n          \"from_parameter\": \"_openeo_user\"  // Will provide the full User object\n        }\n      }\n    }\n  }\n}\n</code></pre></p> </li> </ol> <pre><code>from titiler.openeo.services.auth import ServiceAuthorizationManager\n\n# In your service endpoint:\nservice = services_store.get_service(service_id)\nauth_manager = ServiceAuthorizationManager()\nauth_manager.authorize(service, user)  # Raises HTTPException if access denied\n</code></pre>"},{"location":"authorization/#authorization-flow","title":"Authorization Flow","text":"<ol> <li>Client requests a service endpoint</li> <li>Service configuration is retrieved from the store</li> <li>ServiceAuthorizationManager validates access based on:</li> <li>Service scope</li> <li>User authentication status</li> <li>User authorization (for restricted services)</li> <li>If access is denied:</li> <li>401 Unauthorized - For missing authentication</li> <li>403 Forbidden - For insufficient permissions</li> <li>If access is granted, the request proceeds to service execution</li> </ol>"},{"location":"authorization/#best-practices","title":"Best Practices","text":"<ol> <li>Always set an appropriate scope for your services</li> <li>Use <code>private</code> scope by default for maximum security</li> <li>For restricted services, explicitly list authorized users</li> <li>Consider using <code>public</code> scope only for non-sensitive data</li> <li>Regularly audit service configurations and access patterns</li> </ol>"},{"location":"concepts/","title":"Core Concepts","text":"<p>This document explains the core concepts and data models used in openEO by TiTiler.</p>"},{"location":"concepts/#data-model","title":"Data Model","text":"<p>In openEO, a datacube is a fundamental concept and a key component of the platform. While traditional openEO implementations use multi-dimensional arrays for data representation, openEO by TiTiler simplifies this concept by focusing on image raster data that can be processed on-the-fly and served as tiles or as light dynamic raw data.</p>"},{"location":"concepts/#resolution-and-dimension-management","title":"Resolution and Dimension Management","text":"<p>The backend intelligently handles resolution and dimensions using these key principles:</p> <ol> <li>Default Resolution Control: </li> <li>The <code>load_collection</code> and <code>load_collection_and_reduce</code> processes default to a width of 1024 pixels</li> <li>This intentionally avoids loading data at native resolution by default, which could cause memory issues</li> <li>Users can explicitly request native resolution by providing their own width/height parameters</li> <li> <p>The default provides a good balance between quality and performance</p> </li> <li> <p>Native Resolution Access:</p> </li> <li>Resolution information is extracted from source metadata (transform or shape)</li> <li>When width/height parameters are provided, proportions are maintained</li> <li> <p>Resolution is adjusted based on the requested spatial extent</p> </li> <li> <p>Early Resolution Optimization:</p> </li> <li>Resolution is determined during initial data loading</li> <li>Cropping adjusts resolution proportionally</li> <li>CRS reprojection accounts for resolution changes</li> </ol>"},{"location":"concepts/#raster-data-model","title":"Raster Data Model","text":"<p>The backend uses three primary data structures for efficient processing:</p> <ol> <li>ImageData: Most processes use <code>ImageData</code> objects provided by rio-tiler for individual raster operations. This object was initially designed to create slippy map tiles from large raster data sources and render these tiles dynamically on a web map. Each ImageData object inherently has two spatial dimensions (height and width).</li> </ol> <p></p> <ol> <li>RasterStack: A dictionary mapping names/dates to ImageData objects, allowing for consistent handling of multiple raster layers. This is our implementation of the openEO data cube concept, with some key characteristics:</li> <li>An empty data cube is represented as an empty dictionary (<code>{}</code>)</li> <li>When there is at least one raster in the stack, it has a minimum of 2 dimensions (the spatial dimensions from the raster data)</li> <li>Additional dimensions (like temporal or bands) can be added, but they must be compatible with the existing spatial dimensions</li> <li> <p>Spatial dimensions are inherent to the raster data and cannot be added separately</p> </li> <li> <p>LazyRasterStack: An optimized version of RasterStack that lazily loads data when accessed. This improves performance by only executing processing tasks when the data is actually needed.</p> </li> </ol>"},{"location":"concepts/#dimension-handling","title":"Dimension Handling","text":"<p>The data cube implementation in openEO by TiTiler follows these principles for dimension handling:</p> <ol> <li> <p>Spatial Dimensions: Every raster in the stack has two spatial dimensions (height and width) that are inherent to the data. These dimensions cannot be added or removed through processes, as they are fundamental to the raster data structure.</p> </li> <li> <p>Additional Dimensions: Non-spatial dimensions can be added to the data cube:</p> </li> <li>Temporal dimension: For time series data (e.g., \"2021-01\", \"2021-02\")</li> <li>Bands dimension: For spectral bands (e.g., \"red\", \"green\", \"blue\")</li> <li> <p>Other dimensions: For any other type of categorization</p> </li> <li> <p>Dimension Compatibility: When adding dimensions to a non-empty data cube, the new dimension must be compatible with the existing spatial dimensions. This means any ImageData added to the stack must match the height and width of existing rasters.</p> </li> <li> <p>Empty Data Cubes: An empty data cube (<code>{}</code>) can receive any non-spatial dimension. The first raster data added to the cube will establish the spatial dimensions that all subsequent data must match.</p> </li> </ol>"},{"location":"concepts/#data-reduction","title":"Data Reduction","text":"<p>The ImageData object is obtained by reducing as early as possible the data from the collections. While both <code>load_collection</code> and <code>load_collection_and_reduce</code> processes are available, it's recommended to use <code>load_collection_and_reduce</code> to immediately get an <code>imagedata</code> object at the desired resolution. This approach:</p> <ol> <li>Uses a default width of 1024 pixels to prevent memory issues</li> <li>Allows explicit control over resolution through width/height parameters</li> <li>Performs data reduction at the target resolution</li> <li>Maintains proper proportions throughout the process</li> </ol> <p></p> <p>The reduce process includes a parameter to choose the pixel selection method:</p> <ul> <li><code>first</code> (default): selects the first pixel value</li> <li><code>highest</code>, <code>lowest</code>: selects extreme values</li> <li><code>mean</code>, <code>median</code>, <code>stddev</code>: statistical measures</li> <li><code>lastbandlow</code>, <code>lastbandhigh</code>, <code>lastbandavg</code>: band-specific selections</li> <li><code>count</code>: number of valid pixels</li> </ul>"},{"location":"concepts/#collections-and-stac-integration","title":"Collections and STAC Integration","text":"<p>openEO by TiTiler integrates with external STAC API services to provide collections. It uses <code>pystac-client</code> to proxy the STAC API, configured through the <code>TITILER_OPENEO_SERVICE_STORE_URL</code> environment variable.</p>"},{"location":"concepts/#openeo-process-graph-to-cql2-json-conversion","title":"OpenEO Process Graph to CQL2-JSON Conversion","text":"<p>The backend automatically converts OpenEO process graphs to CQL2-JSON format for STAC API filtering. Supported operators include:</p> <ul> <li>Comparison operators (<code>eq</code>, <code>neq</code>, <code>lt</code>, <code>lte</code>, <code>gt</code>, <code>gte</code>, <code>between</code>)</li> <li>Array operators (<code>in</code>, <code>array_contains</code>)</li> <li>Pattern matching operators (<code>starts_with</code>, <code>ends_with</code>, <code>contains</code>)</li> <li>Null checks (<code>is_null</code>)</li> <li>Logical operators (<code>and</code>, <code>or</code>, <code>not</code>)</li> </ul> <p>Example conversion: <pre><code>// OpenEO process graph\n{\n  \"cloud_cover\": {\n    \"process_graph\": {\n      \"cc\": {\n        \"process_id\": \"lt\",\n        \"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": 20}\n      }\n    }\n  }\n}\n\n// Converted to CQL2-JSON\n{\n  \"op\": \"&lt;\",\n  \"args\": [{\"property\": \"properties.cloud_cover\"}, 20]\n}\n</code></pre></p>"},{"location":"concepts/#performance-considerations","title":"Performance Considerations","text":"<p>The backend is optimized for on-the-fly processing and serving of raster data. Key considerations:</p> <ul> <li>Processing time increases with the extent of data</li> <li>Larger extents may lead to timeouts</li> <li>The backend can be easily replicated and scaled</li> <li>No additional middleware required for deployment</li> <li>Resolution is managed automatically to balance quality and performance</li> <li>Memory usage is controlled through:</li> <li>Default width of 1024 pixels in load functions</li> <li>Pixel count limits for larger requests</li> <li>Early resolution optimization</li> </ul>"},{"location":"contributing/","title":"Development - Contributing","text":"<p>Issues and pull requests are more than welcome: github.com/sentinel-hub/titiler-openeo/issues</p> <p>dev install</p> <pre><code>git clone https://github.com/sentinel-hub/titiler-openeo.git\ncd titiler-openeo\n\npython -m pip install -e \".[test,dev]\"\n</code></pre> <p>Authentication Testing with Keycloak</p> <p>The project includes a Keycloak instance for testing OpenID Connect authentication:</p> <ol> <li>Start the development environment: <pre><code>docker compose up\n</code></pre></li> </ol> <p>This will start: - API service at localhost:8081 - openEO Web Editor at localhost:8080 - Keycloak at localhost:8082</p> <ol> <li>Access Keycloak admin console at localhost:8082/admin</li> <li>Username: <code>admin</code></li> <li> <p>Password: <code>admin</code></p> </li> <li> <p>Create a new client:</p> </li> <li>Go to \"Clients\" \u2192 \"Create client\"</li> <li>Client ID: <code>titiler-openeo</code></li> <li>Client type: <code>OpenID Connect</code></li> <li>Click \"Next\"</li> <li>Enable \"Client authentication\"</li> <li>Enable \"Authorization\"</li> <li> <p>Click \"Save\"</p> </li> <li> <p>Configure client settings:</p> </li> <li>Valid redirect URIs: <code>http://localhost:8080/*</code> for the openEO editor</li> <li>Web origins: <code>http://localhost:8080</code> for the openEO editor</li> <li>Click \"Save\"</li> </ol> <p>The environment includes several pre-configured settings: - GDAL optimization settings for performance - Debug mode enabled - STAC API endpoint set to stac.eoapi.dev - Keycloak OIDC configuration</p> <ol> <li>Create a test user:</li> <li>Go to \"Users\" \u2192 \"Add user\"</li> <li>Username: <code>test</code></li> <li>Email: <code>test@example.com</code></li> <li>Click \"Create\"</li> <li>Go to \"Credentials\" tab</li> <li>Set password: <code>test123</code></li> <li>Disable \"Temporary\"</li> <li>Click \"Save password\"</li> </ol> <p>The Keycloak server will be available at localhost:8082 for testing OIDC authentication flows.</p> <p>pre-commit</p> <p>This repo is set to use <code>pre-commit</code> to run isort, flake8, pydocstring, black (\"uncompromising Python code formatter\") and mypy when committing new code.</p> <pre><code>pre-commit install\n</code></pre>"},{"location":"contributing/#run-tests","title":"Run tests","text":"<pre><code>python -m pytest --cov=titiler.openeo --cov-report=xml --cov-append --cov-report=term-missing\n</code></pre>"},{"location":"contributing/#docs","title":"Docs","text":"<pre><code>git clone https://github.com/sentinel-hub/titiler-openeo.git\ncd titiler-openeo\npython -m pip install -e \".[docs]\"\n</code></pre> <p>Hot-reloading docs:</p> <pre><code>mkdocs serve -f docs/mkdocs.yml\n</code></pre> <p>To manually deploy docs (note you should never need to do this because Github Actions deploys automatically for new commits.):</p> <p>```bash mkdocs gh-deploy -f docs/mkdocs.yml</p>"},{"location":"kubernetes/","title":"Kubernetes Deployment Guide","text":"<p>This guide explains how to deploy openEO by TiTiler on Kubernetes using Helm. The implementation is available in the <code>deployment/k8s</code> directory.</p>"},{"location":"kubernetes/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes 1.16+</li> <li>Helm 3.0+</li> <li>PostgreSQL (optional, can be deployed as a subchart)</li> </ul>"},{"location":"kubernetes/#quick-start","title":"Quick Start","text":"<p>For local testing with Minikube:</p> <pre><code># Start Minikube\nminikube start\n\n# Set context\nkubectl config use-context minikube\n\n# Install using Helm\ncd deployment/k8s\nhelm upgrade --install openeo-titiler .\n\n# Enable ingress (if needed)\nminikube addons enable ingress\n\n# Get service URL\nminikube service ingress-nginx-controller -n ingress-nginx --url | head -n 1\n</code></pre>"},{"location":"kubernetes/#configuration","title":"Configuration","text":"<p>For detailed configuration options, refer to the Helm chart README. The README provides comprehensive documentation on:</p> <ul> <li>Global parameters</li> <li>Database configuration (JSON, DuckDB, PostgreSQL)</li> <li>Persistence settings</li> <li>Ingress configuration</li> <li>Resource management</li> <li>Autoscaling options</li> </ul>"},{"location":"kubernetes/#cdse-integration","title":"CDSE Integration","text":"<p>For deploying with Copernicus Data Space Ecosystem (CDSE), follow the instructions in the CDSE deployment section of the Helm chart documentation.</p>"},{"location":"kubernetes/#production-deployment-considerations","title":"Production Deployment Considerations","text":"<p>When deploying to production:</p> <ol> <li>Configure appropriate resource limits and requests</li> <li>Enable and configure persistent storage</li> <li>Set up proper ingress with TLS</li> <li>Configure authentication</li> <li>Tune environment variables for performance</li> <li>Enable monitoring and logging</li> </ol> <p>For specific configuration values and examples, refer to the configuration section in the Helm chart documentation.</p>"},{"location":"kubernetes/#troubleshooting","title":"Troubleshooting","text":""},{"location":"kubernetes/#common-issues","title":"Common Issues","text":"<ol> <li>Pod Startup Failures</li> <li>Check resource limits</li> <li>Verify storage configuration</li> <li> <p>Check logs: <code>kubectl logs -l app=openeo-titiler</code></p> </li> <li> <p>Database Connection Issues</p> </li> <li>Verify database configuration</li> <li>Check connectivity to external database</li> <li> <p>Validate persistent volume claims</p> </li> <li> <p>Ingress Problems</p> </li> <li>Verify ingress controller is running</li> <li>Check ingress configuration</li> <li>Validate TLS certificates</li> </ol> <p>For more details on configuration options and deployment scenarios, see the Helm chart documentation.</p>"},{"location":"local-setup/","title":"Local Setup","text":"<p>This guide explains how to set up openEO by TiTiler locally.</p>"},{"location":"local-setup/#installation","title":"Installation","text":"<p>Clone the repository and install the dependencies:</p> <pre><code>git clone https://github.com/sentinel-hub/titiler-openeo.git\ncd titiler-openeo\npython -m pip install -e .\n</code></pre>"},{"location":"local-setup/#configuration","title":"Configuration","text":""},{"location":"local-setup/#environment-setup","title":"Environment Setup","text":"<p>The application can be configured using different environment files:</p> <ol> <li>EOAPI Configuration (default) <pre><code>cp .env.eoapi .env\nexport $(cat .env | xargs)\n</code></pre></li> </ol> <p>This sets up: <pre><code>TITILER_OPENEO_STAC_API_URL=\"https://stac.eoapi.dev\"\nTITILER_OPENEO_SERVICE_STORE_URL=\"services/eoapi.json\"\n</code></pre></p> <ol> <li>CDSE Configuration <pre><code>cp .env.cdse .env\nexport $(cat .env | xargs)\n</code></pre></li> </ol> <p>This configures: <pre><code>TITILER_OPENEO_STAC_API_URL=\"https://stac.dataspace.copernicus.eu/v1\"\nTITILER_OPENEO_SERVICE_STORE_URL=\"services/copernicus.json\"\n</code></pre></p> <p>For CDSE, additional environment variables are required for efficient data access: <pre><code>AWS_S3_ENDPOINT=eodata.dataspace.copernicus.eu\nAWS_ACCESS_KEY_ID=&lt;your_access_key&gt;\nAWS_SECRET_ACCESS_KEY=&lt;your_secret_key&gt;\nAWS_VIRTUAL_HOSTING=FALSE\nCPL_VSIL_CURL_CACHE_SIZE=200000000\nGDAL_HTTP_MULTIPLEX=TRUE\nGDAL_CACHEMAX=500\nGDAL_INGESTED_BYTES_AT_OPEN=50000\nGDAL_HTTP_MERGE_CONSECUTIVE_RANGES=YES\nVSI_CACHE_SIZE=5000000\nVSI_CACHE=TRUE\n</code></pre></p>"},{"location":"local-setup/#running-the-application","title":"Running the Application","text":"<p>Start the server: <pre><code>uvicorn titiler.openeo.main:app --host 0.0.0.0 --port 8080\n</code></pre></p> <p>The API will be available at <code>http://localhost:8080</code></p>"},{"location":"local-setup/#using-the-openeo-editor","title":"Using the openEO Editor","text":"<p>To use the openEO Web Editor with your local instance:</p> <ol> <li> <p>Start the openEO Web Editor: <pre><code>docker pull mundialis/openeo-web-editor:latest\ndocker run -p 8081:80 mundialis/openeo-web-editor:latest\n</code></pre></p> </li> <li> <p>Access the editor at <code>http://localhost:8081</code></p> </li> <li> <p>Configure the editor:</p> </li> <li>Set backend URL to <code>http://localhost:8080</code></li> <li>Login with the default basic auth credentials:<ul> <li>Username: <code>test</code></li> <li>Password: <code>test</code></li> </ul> </li> </ol>"},{"location":"openid-connect/","title":"OpenID Connect Configuration","text":"<p>TiTiler-OpenEO supports OpenID Connect (OIDC) authentication following the OpenEO authentication model. The implementation supports the OpenID Connect Authorization Code Flow with PKCE.</p> <p>The implementation is available in <code>titiler/openeo/auth.py</code> with the main class being <code>OIDCAuth</code>.</p>"},{"location":"openid-connect/#openeo-authentication-model","title":"OpenEO Authentication Model","text":"<p>TiTiler-OpenEO follows the OpenEO authentication specification where tokens are provided in the format: <pre><code>Bearer oidc/oidc/{actual_token}\n</code></pre></p> <p>The token structure consists of three parts: 1. Authentication method (<code>oidc</code>) 2. Provider identifier (<code>oidc</code>) 3. The actual OIDC token</p> <p>Token parsing is handled by the <code>AuthToken</code> class.</p>"},{"location":"openid-connect/#configuration","title":"Configuration","text":"<p>The OIDC configuration is managed through <code>OIDCConfig</code> in the settings. To enable OpenID Connect authentication, configure the following environment variables:</p> <pre><code>TITILER_OPENEO_AUTH_METHOD=oidc\nTITILER_OPENEO_AUTH_OIDC_CLIENT_ID=\"your-client-id\"\nTITILER_OPENEO_AUTH_OIDC_WK_URL=\"https://your-provider/.well-known/openid-configuration\"\nTITILER_OPENEO_AUTH_OIDC_REDIRECT_URL=\"your-redirect-url\"\n</code></pre> <p>Optional configuration: <pre><code>TITILER_OPENEO_AUTH_OIDC_SCOPES=\"openid email profile\"  # Space-separated list (default)\nTITILER_OPENEO_AUTH_OIDC_NAME_CLAIM=\"name\"  # Claim to use for user name (default)\nTITILER_OPENEO_AUTH_OIDC_TITLE=\"OIDC\"  # Provider title (default)\nTITILER_OPENEO_AUTH_OIDC_DESCRIPTION=\"OpenID Connect (OIDC) Authorization Code Flow with PKCE\"  # Provider description (default)\n</code></pre></p>"},{"location":"openid-connect/#token-validation","title":"Token Validation","text":"<p>The OIDC implementation performs the following validations in the <code>_verify_token</code> method:</p> <ol> <li>Verifies the token signature using the provider's JWKS</li> <li>Validates token claims including:</li> <li>Client ID matches the configured one</li> <li>Token expiration</li> <li>Token audience</li> </ol>"},{"location":"openid-connect/#user-information","title":"User Information","text":"<p>Upon successful validation, a <code>User</code> object is created with: - <code>user_id</code>: Subject claim from the token (<code>sub</code>) - <code>email</code>: Email claim if available - <code>name</code>: Value from the configured name claim (defaults to \"name\")</p>"},{"location":"openid-connect/#security-considerations","title":"Security Considerations","text":"<ul> <li>Keep your client ID secure</li> <li>Configure appropriate token expiration times</li> <li>Use HTTPS in production</li> <li>Review and limit the requested scopes</li> <li>Regularly rotate any client secrets if used</li> </ul> <p>For more details on the implementation, see the auth module source code.</p>"},{"location":"project-overview/","title":"Project Overview","text":""},{"location":"project-overview/#about-openeo-by-titiler","title":"About openEO by TiTiler","text":"<p>openEO by TiTiler is a fast and lightweight implementation of the openEO API, developed by Development Seed. It provides efficient management of raster-based processes using the TiTiler engine.</p>"},{"location":"project-overview/#context","title":"Context","text":"<p>openEO serves as an abstraction layer for Earth Observation (EO) processing and has gained significant traction within the community. Several data hubs now offer openEO as a service, notably the Copernicus Data Space Ecosystem, Terrascope, and EODC. Additionally, EOEPCA+, with its processing building block, is furthering the deployment of openEO.</p>"},{"location":"project-overview/#features","title":"Features","text":"<p>The main features include:</p> <ul> <li>Built on top of FastAPI</li> <li>Cloud Optimized GeoTIFF support</li> <li>SpatioTemporal Asset Catalog support</li> <li>Multiple projections support via morecantile</li> <li>JPEG / PNG / Geotiff / JSON / CSV output format support</li> <li>XYZ secondary service support</li> <li>Automatic OpenAPI documentation</li> </ul>"},{"location":"project-overview/#api-support","title":"API Support","text":"<p>The application implements the openEO API (L1A and L1C) profiles:</p> <ul> <li>Synchronous Processing (L1A): For direct processing and downloading of data</li> <li>Secondary Web Services (L1C): For data visualization with dynamic tiling</li> </ul>"},{"location":"project-overview/#project-goals","title":"Project Goals","text":"<p>The primary objectives of this project are:</p> <ol> <li>Provide a lightweight and fast backend for openEO services</li> <li>Focus on efficient raster data processing</li> <li>Enable dynamic tiling and visualization capabilities</li> <li>Maintain compatibility with STAC API services</li> <li>Deliver high-performance synchronous processing</li> </ol>"},{"location":"raster-stack/","title":"RasterStack Data Model","text":"<p>In titiler-openeo, the RasterStack data model is central to how raster data is represented and processed throughout the system. This document explains the RasterStack concept, its implementation, and the performance benefits it provides.</p>"},{"location":"raster-stack/#overview","title":"Overview","text":"<p>The RasterStack is a dictionary-like structure that maps names or dates to <code>ImageData</code> objects, allowing for consistent handling of multiple raster layers. This approach simplifies the processing of Earth Observation data by providing a unified interface for operations on raster data.</p> <pre><code># Example of RasterStack structure\nRasterStack = {\n    \"2023-01-01\": ImageData(...),  # First date\n    \"2023-01-15\": ImageData(...),  # Second date\n    \"2023-02-01\": ImageData(...),  # Third date\n}\n</code></pre>"},{"location":"raster-stack/#imagedata-vs-rasterstack","title":"ImageData vs RasterStack","text":"<ul> <li>ImageData: Single raster layer, with dimensions, bounds, CRS, and metadata</li> <li>RasterStack: Collection of named ImageData objects, typically representing different dates or bands</li> </ul>"},{"location":"raster-stack/#lazyrasterstack","title":"LazyRasterStack","text":"<p>The LazyRasterStack extends the basic RasterStack concept by implementing lazy loading of data:</p> <pre><code># LazyRasterStack only loads data when accessed\nraster_stack = LazyRasterStack(tasks, date_name_fn)\n\n# Data is only loaded when accessed\nimage_data = raster_stack[\"2023-01-01\"]  # This triggers loading\n</code></pre>"},{"location":"raster-stack/#key-features-of-lazyrasterstack","title":"Key Features of LazyRasterStack","text":"<ol> <li>On-demand Loading: Data is loaded only when actually accessed, reducing memory usage for large collections</li> <li>Task-based Execution: Uses rio-tiler's task system to efficiently process data</li> <li>Exception Handling: Gracefully handles common exceptions like TileOutsideBounds</li> <li>Dictionary Interface: Maintains the familiar dictionary interface for easy integration</li> </ol>"},{"location":"raster-stack/#advantages-of-the-rasterstack-model","title":"Advantages of the RasterStack Model","text":"<ul> <li>Consistency: All processes now use a consistent data structure</li> <li>Performance: LazyRasterStack reduces memory footprint and improves performance</li> <li>Predictability: Standardized input/output for all operations</li> <li>Flexibility: Works well with time series and multi-band data</li> </ul>"},{"location":"raster-stack/#how-processing-works-with-rasterstack","title":"How Processing Works with RasterStack","text":""},{"location":"raster-stack/#load-phase","title":"Load Phase","text":"<p>Data is loaded from collections into a LazyRasterStack structure:</p> <pre><code># Process graph example\n{\n  \"process_id\": \"load_collection\",\n  \"arguments\": {\n    \"id\": \"sentinel-2-l2a\",\n    \"spatial_extent\": {...},\n    \"temporal_extent\": [\"2023-01-01\", \"2023-03-01\"],\n    \"bands\": [\"B04\", \"B08\"]\n  }\n}\n</code></pre>"},{"location":"raster-stack/#process-phase","title":"Process Phase","text":"<p>Operations are applied uniformly to items in the RasterStack:</p> <pre><code># Process graph example to calculate NDVI\n{\n  \"process_id\": \"normalized_difference\",\n  \"arguments\": {\n    \"x\": {\"from_node\": \"load_collection\", \"band\": \"B08\"},\n    \"y\": {\"from_node\": \"load_collection\", \"band\": \"B04\"}\n  }\n}\n</code></pre>"},{"location":"raster-stack/#output-phase","title":"Output Phase","text":"<p>Results are rendered as a single image or maintained as a RasterStack:</p> <pre><code># Process graph example to save result\n{\n  \"process_id\": \"save_result\",\n  \"arguments\": {\n    \"data\": {\"from_node\": \"normalized_difference\"},\n    \"format\": \"png\"\n  }\n}\n</code></pre>"},{"location":"raster-stack/#code-examples","title":"Code Examples","text":"<p>Handling a RasterStack with basic operations:</p> <pre><code># Convert a single ImageData to a RasterStack\nfrom titiler.openeo.processes.implementations.data_model import to_raster_stack\n\nimg_data = ImageData(...)\nraster_stack = to_raster_stack(img_data)  # {\"data\": img_data}\n\n# Process each image in a RasterStack consistently\ndef apply_to_raster_stack(raster_stack, func):\n    \"\"\"Apply a function to each ImageData in a RasterStack\"\"\"\n    return {k: func(v) for k, v in raster_stack.items()}\n</code></pre>"},{"location":"raster-stack/#performance-benefits","title":"Performance Benefits","text":"<p>The LazyRasterStack implementation provides several performance benefits:</p> <ol> <li>Memory Efficiency: Only loads data that is actually used</li> <li>Computation Efficiency: Defers expensive computations until needed</li> <li>Error Resilience: Handles exceptions during computation without failing the entire process</li> <li>Scalability: Better handles large datasets with many dates/bands</li> </ol>"},{"location":"raster-stack/#best-practices","title":"Best Practices","text":"<p>When working with the RasterStack data model:</p> <ol> <li>Use <code>to_raster_stack()</code> to ensure consistent handling of both single images and collections</li> <li>Prefer using LazyRasterStack for large collections</li> <li>Design processes to operate on RasterStack inputs and produce RasterStack outputs</li> <li>Use the dictionary interface (keys, values, items) for flexible processing</li> </ol>"},{"location":"release-notes/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"release-notes/#unreleased","title":"[Unreleased]","text":""},{"location":"release-notes/#added","title":"Added","text":"<ul> <li>Add user tracking functionality across all store implementations (SQLAlchemy, DuckDB, Local) to monitor user authentication history and activity</li> </ul>"},{"location":"release-notes/#030-2025-06-04","title":"[0.3.0] (2025-06-04)","text":""},{"location":"release-notes/#added_1","title":"Added","text":"<ul> <li>Added force-release functionality for tile assignment and update documentation #96</li> <li>Added tile update functionality #97</li> <li>Add width and height parameters to load_collection and load_collection_and_reduce processes #99</li> <li>Add tiles_summary process and implement get_all_tiles method in TileAssignmentStore #101</li> <li>Add max and min functions with no-data handling #102</li> </ul>"},{"location":"release-notes/#fixed","title":"Fixed","text":"<ul> <li>Enhances pixel limit check to avoid double counting mosaic items by grouping them by datetime. #98</li> </ul>"},{"location":"release-notes/#changed","title":"Changed","text":"<ul> <li>Refactor tile assignment and add spatial extent handling #100</li> <li>Refactor STAC reader and enhance output dimension handling #103</li> <li>Refactor STAC item handling and enhance metadata retrieval #104</li> </ul>"},{"location":"release-notes/#021-2025-05-21","title":"0.2.1 (2025-05-21)","text":""},{"location":"release-notes/#added_2","title":"Added","text":"<ul> <li>Added force-release functionality for tile assignment to release tiles regardless of state</li> </ul>"},{"location":"release-notes/#changed_1","title":"Changed","text":"<ul> <li>Fix load_collection to properly merge items from same date to maintain strict temporal dimension #93</li> <li>Improve error handling for output size limits with clearer error messages and proper pixel count calculation #94</li> </ul>"},{"location":"release-notes/#020-2025-05-19","title":"0.2.0 (2025-05-19)","text":""},{"location":"release-notes/#added_3","title":"Added","text":"<ul> <li>OpenEO process graph to CQL2-JSON conversion feature #65</li> <li>Output size estimation and validation #58</li> <li>NDWI process implementation #67</li> <li><code>load_url</code> process for direct COG loading #70</li> <li>PostgreSQL subchart support #73</li> <li>Support for default services configuration #74</li> <li>DynamicCacheControlMiddleware for improved cache management #78</li> <li>Tile assignment functionality with SQLAlchemy integration #80</li> <li>Service authorization management for restricted access #81</li> <li>get_param_item process for JSONPath extraction #82</li> </ul>"},{"location":"release-notes/#changed_2","title":"Changed","text":"<ul> <li>Implement lazy rasterstack #62</li> <li>Refactor processes to standardize data types to 'datacube' #68</li> <li>Enhance navigation structure and improve documentation readability #72</li> <li>Enhance service input validation and handling logic #77</li> <li>Enhance process nodes with user parameter handling #79</li> <li>Enhance tile assignment process with user control #83</li> <li>Enhance user parameter handling in processes #84</li> </ul>"},{"location":"release-notes/#fixed_1","title":"Fixed","text":"<ul> <li>Add check for version sync #49</li> </ul>"},{"location":"release-notes/#010-2025-04-07","title":"0.1.0 (2025-04-07)","text":"<p>Initial release of openEO by TiTiler</p>"},{"location":"tile-assignment/","title":"Tile Assignment","text":"<p>The tile assignment feature allows services to manage and track XYZ tile assignments to users. This is particularly useful for scenarios where you need to coordinate work across multiple users, ensuring each user works on unique tiles without overlap.</p>"},{"location":"tile-assignment/#setup","title":"Setup","text":"<p>The tile assignment feature requires two levels of configuration:</p> <ol> <li> <p>Global Configuration:    <pre><code># Enable tile assignment with SQLAlchemy store\nTITILER_OPENEO_TILE_STORE_URL=postgresql://user:pass@host/db\n</code></pre></p> </li> <li> <p>Service Configuration:    <pre><code>{\n  \"type\": \"XYZ\",\n  \"configuration\": {\n    \"tile_store\": true,\n    ...other configuration options...\n  }\n}\n</code></pre></p> </li> </ol> <p>The feature will only be active when both: - A valid tile store URL is configured at the system level - The service has <code>tile_store: true</code> in its configuration (this will inject the store as \"_openeo_tile_store\" parameter)</p> <p>To access the injected tile store in your process graph, use the <code>from_parameter</code> reference:</p> <pre><code>{\n  \"process_graph\": {\n    \"tile_assignment1\": {\n      \"process_id\": \"tile_assignment\",\n      \"arguments\": {\n        \"store\": {\n          \"from_parameter\": \"_openeo_tile_store\"\n        },\n        \"zoom\": 12,\n        \"x_range\": [1000, 1010],\n        \"y_range\": [2000, 2010],\n        \"stage\": \"claim\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"tile-assignment/#supported-store-types","title":"Supported Store Types","text":"<p>Currently supported tile store implementations: - PostgreSQL: <code>postgresql://user:pass@host/db</code> - SQLite: <code>sqlite:///path/to/db.sqlite</code> - SQLAlchemy URL: <code>sqlalchemy://...</code></p>"},{"location":"tile-assignment/#process-parameters","title":"Process Parameters","text":"<p>The tile assignment process is defined with the following JSON schema:</p> <pre><code>{\n  \"parameters\": {\n    \"zoom\": {\n      \"description\": \"Fixed zoom level for tile assignment\",\n      \"type\": \"integer\",\n      \"required\": true\n    },\n    \"x_range\": {\n      \"description\": \"Range of possible X values [min, max]\",\n      \"type\": \"array\",\n      \"items\": {\"type\": \"integer\"},\n      \"minItems\": 2,\n      \"maxItems\": 2,\n      \"required\": true\n    },\n    \"y_range\": {\n      \"description\": \"Range of possible Y values [min, max]\",\n      \"type\": \"array\",\n      \"items\": {\"type\": \"integer\"},\n      \"minItems\": 2,\n      \"maxItems\": 2,\n      \"required\": true\n    },\n    \"stage\": {\n      \"description\": \"Stage of tile assignment\",\n      \"type\": \"string\",\n      \"enum\": [\"claim\", \"release\", \"submit\", \"force-release\"],\n      \"required\": true\n    },\n    \"user_id\": {\n      \"description\": \"User identifier for tile assignment\",\n      \"type\": \"string\",\n      \"required\": true\n    },\n  }\n}\n</code></pre> <p>Because <code>user_id</code> is defined with <code>\"type\": \"string\"</code>, when using <code>from_parameter: \"_openeo_user\"</code>, it will automatically extract just the user ID from the User object.</p>"},{"location":"tile-assignment/#access-control","title":"Access Control","text":"<p>The tile assignment process ensures that each tile can only be managed by the user who claimed it.  Each operation (release/submit/force-release) requires a valid tile assignment - a user must have  a claimed tile to perform any operation on it.</p>"},{"location":"tile-assignment/#usage-example","title":"Usage Example","text":"<p>Here's an example of using the tile assignment process in a service:</p> <pre><code>{\n  \"process_graph\": {\n    \"tile_assignment1\": {\n      \"process_id\": \"tile_assignment\",\n      \"arguments\": {\n        \"zoom\": 12,\n        \"x_range\": [1000, 1010],\n        \"y_range\": [2000, 2010],\n        \"stage\": \"claim\",\n        \"user_id\": \"user123\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"tile-assignment/#workflow","title":"Workflow","text":"<ol> <li>Claiming a Tile:</li> <li>User requests a tile with stage=\"claim\"</li> <li>System randomly assigns an available tile within the specified ranges</li> <li>If user already has a tile assigned, returns that tile instead</li> <li> <p>If no tiles are available, raises an error</p> </li> <li> <p>Releasing a Tile:</p> </li> <li>User releases their tile with stage=\"release\"</li> <li>Tile becomes available for other users to claim</li> <li>Cannot release a submitted tile without force-release</li> <li>Only the owner can release their tile</li> <li> <p>Error if another user tries to release it</p> </li> <li> <p>Submitting a Tile:</p> </li> <li>User submits their tile with stage=\"submit\"</li> <li>Tile becomes locked and cannot be released normally</li> <li>Only the owner of the tile can submit it</li> <li> <p>Submitted tiles can only be released using force-release</p> </li> <li> <p>Force-releasing a Tile:</p> </li> <li>User can force-release their tile with stage=\"force-release\"</li> <li>Works on any tile state (claimed or submitted)</li> <li>Only the owner of the tile can force-release it</li> <li> <p>Useful for recovering tiles that are stuck in submitted state</p> </li> <li> <p>Updating a Tile:</p> </li> <li>User can add or update additional information to their assigned tile</li> <li>Supports arbitrary JSON data for tracking progress, metadata, etc.</li> <li>Additional data persists and is returned in subsequent queries</li> <li>Only the tile owner can update their tile in controlled mode</li> <li>Common use cases:<ul> <li>Progress tracking (e.g., percent complete)</li> <li>Processing metadata (start time, end time)</li> <li>Quality metrics</li> <li>Custom workflow data</li> </ul> </li> </ol>"},{"location":"tile-assignment/#error-handling","title":"Error Handling","text":"<p>The process handles several error conditions:</p> <ul> <li><code>NoTileAvailableError</code>: When trying to claim a tile but none are available</li> <li><code>TileNotAssignedError</code>: When trying to release/submit a tile but user has none assigned</li> <li><code>TileAlreadyLockedError</code>: When trying to release a submitted tile</li> </ul>"},{"location":"tile-assignment/#implementation-details","title":"Implementation Details","text":"<p>The tile assignment system: - Maintains persistent tile assignments using SQLAlchemy - Ensures unique tile assignments (no two users can have the same tile) - Randomly distributes tiles to prevent predictable assignment patterns - Supports multiple services with independent tile assignments - Tracks tile state (claimed/released/submitted)</p>"},{"location":"tile-assignment/#best-practices","title":"Best Practices","text":"<ol> <li>Range Selection:</li> <li>Choose appropriate x_range and y_range based on your data coverage</li> <li>Consider zoom level when determining range size</li> <li> <p>Avoid overlapping ranges between different services</p> </li> <li> <p>Error Handling:</p> </li> <li>Always handle potential errors in your client code</li> <li>Implement retry logic for NoTileAvailableError</li> <li> <p>Verify tile assignment before starting work</p> </li> <li> <p>State Management:</p> </li> <li>Submit completed tiles to prevent accidental release</li> <li>Release tiles when work is abandoned</li> <li>Check existing assignments before claiming new tiles</li> </ol>"},{"location":"examples/","title":"Examples","text":"<p>This section provides practical examples of using openEO by TiTiler for various Earth Observation tasks.</p>"},{"location":"examples/#web-editor-examples","title":"Web Editor Examples","text":"<p>The openEO Web Editor provides a graphical interface for interacting with the API. To get started:</p> <ol> <li>Start the services:</li> </ol> <pre><code>docker compose up\n</code></pre> <ol> <li> <p>Access the editor at localhost:8080 and set the backend URL to localhost:8081</p> </li> <li> <p>Authenticate using the instructions in the Admin Guide</p> </li> </ol>"},{"location":"examples/#jupyter-notebook-examples","title":"Jupyter Notebook Examples","text":"<p>We provide several Jupyter notebooks demonstrating different use cases:</p>"},{"location":"examples/#manhattan-satellite-imagery","title":"Manhattan Satellite Imagery","text":"<p>Learn how to:</p> <ul> <li>Connect to the openEO backend</li> <li>Load and process Sentinel-2 imagery using default resolution (1024 pixels width)</li> <li>Control output resolution with explicit width/height parameters</li> <li>Create true-color RGB visualizations</li> <li>Apply color enhancements for better visualization</li> </ul>"},{"location":"examples/#ndvi-time-series-analysis","title":"NDVI Time Series Analysis","text":"<p>Explore how to:</p> <ul> <li>Calculate vegetation indices (NDVI)</li> <li>Extract time series data for specific areas</li> <li>Control memory usage with appropriate resolution settings</li> <li>Analyze temporal patterns in vegetation</li> <li>Visualize results using matplotlib</li> </ul>"},{"location":"examples/#resolution-control-examples","title":"Resolution Control Examples","text":"<p>The examples demonstrate different approaches to managing resolution:</p> <ol> <li> <p>Default Resolution: <pre><code>loadcol = load_collection_and_reduce(\n    \"SENTINEL2_L2A\",\n    spatial_extent=bbox,\n    temporal_extent=[\"2021-01-01\", \"2021-12-31\"],\n    bands=[\"B04\", \"B08\"]\n)\n# Uses default width of 1024 pixels for memory efficiency\n</code></pre></p> </li> <li> <p>Custom Resolution: <pre><code>loadcol = load_collection_and_reduce(\n    \"SENTINEL2_L2A\",\n    spatial_extent=bbox,\n    temporal_extent=[\"2021-01-01\", \"2021-12-31\"],\n    bands=[\"B04\", \"B08\"],\n    width=2048,  # Explicitly control resolution\n)\n</code></pre></p> </li> </ol>"},{"location":"examples/#running-the-notebooks","title":"Running the Notebooks","text":"<p>To run the notebooks locally:</p> <ol> <li>Install the development dependencies:</li> </ol> <pre><code>python -m pip install -e \".[dev]\"\n</code></pre> <ol> <li>Start Jupyter:</li> </ol> <pre><code>jupyter notebook docs/notebooks\n</code></pre> <ol> <li>Open the desired notebook and follow the instructions</li> </ol>"},{"location":"notebooks/load_raster_stack/","title":"STAC Collections and Items","text":"In\u00a0[\u00a0]: Copied! <pre>import openeo\n\n# Connect to the back-end\nconnection = openeo.connect(\"http://127.0.0.1:8081/\")\n# ToDo: Here you need to authenticate with authenticate_basic() or authenticate_oidc()\nconnection.authenticate_oidc()\n\nurl = \"https://stac.dataspace.copernicus.eu/v1/collections/sentinel-2-l2a\"\nspatial_extent = {\"west\": 11, \"east\": 12, \"south\": 46, \"north\": 47}\ntemporal_extent = [\"2019-01-01\", \"2019-01-15\"]\nbands = [\"B04_60m\"]\nproperties = {\"eo:cloud_cover\": {\"lt\": 50}}\ns2_cube = connection.load_stac(url=url,\n    spatial_extent=spatial_extent,\n    temporal_extent=temporal_extent,\n    bands=bands,\n    # properties=properties,\n)\ns2_cube.execute()\n</pre> import openeo  # Connect to the back-end connection = openeo.connect(\"http://127.0.0.1:8081/\") # ToDo: Here you need to authenticate with authenticate_basic() or authenticate_oidc() connection.authenticate_oidc()  url = \"https://stac.dataspace.copernicus.eu/v1/collections/sentinel-2-l2a\" spatial_extent = {\"west\": 11, \"east\": 12, \"south\": 46, \"north\": 47} temporal_extent = [\"2019-01-01\", \"2019-01-15\"] bands = [\"B04_60m\"] properties = {\"eo:cloud_cover\": {\"lt\": 50}} s2_cube = connection.load_stac(url=url,     spatial_extent=spatial_extent,     temporal_extent=temporal_extent,     bands=bands,     # properties=properties, ) s2_cube.execute()"},{"location":"notebooks/load_raster_stack/#stac-collections-and-items","title":"STAC Collections and Items\u00b6","text":"<p>With the <code>load_stac</code> process it's possible to load and use data provided by remote or local STAC Collections or Items. The following code snippet loads Sentinel-2 L2A data from a public STAC Catalog, using specific spatial and temporal extent, band name and also properties for cloud coverage.</p>"},{"location":"notebooks/manhattan/","title":"Manhattan Satellite Imagery Analysis with OpenEO","text":"In\u00a0[8]: Copied! <pre># Import required packages\n\nimport openeo\nfrom openeo.processes import process\nfrom IPython.display import Image\n</pre> # Import required packages  import openeo from openeo.processes import process from IPython.display import Image In\u00a0[9]: Copied! <pre># Connect to the back-end\n\n#connection = openeo.connect(\"https://openeo.ds.io\").authenticate_oidc()\nconnection = openeo.connect(url=\"http://127.0.0.1:8081/\").authenticate_oidc()\n</pre> # Connect to the back-end  #connection = openeo.connect(\"https://openeo.ds.io\").authenticate_oidc() connection = openeo.connect(url=\"http://127.0.0.1:8081/\").authenticate_oidc() <pre>Authenticated using refresh token.\n</pre> In\u00a0[10]: Copied! <pre>spatial_extent_east = -73.90\nspatial_extent_north = 40.80\nspatial_extent_south = 40.70\nspatial_extent_west = -74.00\n</pre> spatial_extent_east = -73.90 spatial_extent_north = 40.80 spatial_extent_south = 40.70 spatial_extent_west = -74.00 In\u00a0[11]: Copied! <pre>load1 = connection.datacube_from_process(\n    \"load_collection_and_reduce\",\n    id=\"sentinel-2-global-mosaics\",\n    bands=[\"B04\", \"B03\", \"B02\"],\n    properties={},\n    spatial_extent={\n        \"east\": spatial_extent_east,\n        \"north\": spatial_extent_north,\n        \"south\": spatial_extent_south,\n        \"west\": spatial_extent_west,\n    },\n    temporal_extent=[\"2022-04-15T00:00:00Z\", \"2022-12-31T00:00:00Z\"],\n    pixel_selection=\"first\"\n)\n</pre> load1 = connection.datacube_from_process(     \"load_collection_and_reduce\",     id=\"sentinel-2-global-mosaics\",     bands=[\"B04\", \"B03\", \"B02\"],     properties={},     spatial_extent={         \"east\": spatial_extent_east,         \"north\": spatial_extent_north,         \"south\": spatial_extent_south,         \"west\": spatial_extent_west,     },     temporal_extent=[\"2022-04-15T00:00:00Z\", \"2022-12-31T00:00:00Z\"],     pixel_selection=\"first\" ) In\u00a0[12]: Copied! <pre>def process1(x, context = None):\n    data1 = process(\"linear_scale_range\", inputMax = 10000, inputMin = 0, outputMax = 255, x = x)\n    data2 = process(\"trunc\", x = data1)\n    return data2\n</pre> def process1(x, context = None):     data1 = process(\"linear_scale_range\", inputMax = 10000, inputMin = 0, outputMax = 255, x = x)     data2 = process(\"trunc\", x = data1)     return data2 In\u00a0[13]: Copied! <pre>processed = load1.apply(process = process1)\n\ncolor = processed.process(\n    \"color_formula\",\n    data=processed,\n    formula=\"Gamma RGB 1.5 Sigmoidal RGB 10 0.3 Saturation 1\",\n)\n</pre> processed = load1.apply(process = process1)  color = processed.process(     \"color_formula\",     data=processed,     formula=\"Gamma RGB 1.5 Sigmoidal RGB 10 0.3 Saturation 1\", ) In\u00a0[14]: Copied! <pre>save5 = color.save_result(format=\"PNG\")\n\n# The process can be executed synchronously (see below), as batch job or as web service now\nresult = connection.download(save5)\nImage(result)\n</pre> save5 = color.save_result(format=\"PNG\")  # The process can be executed synchronously (see below), as batch job or as web service now result = connection.download(save5) Image(result) Out[14]:"},{"location":"notebooks/manhattan/#manhattan-satellite-imagery-analysis-with-openeo","title":"Manhattan Satellite Imagery Analysis with OpenEO\u00b6","text":""},{"location":"notebooks/manhattan/#overview","title":"Overview\u00b6","text":"<p>This notebook demonstrates how to retrieve and visualize satellite imagery of Manhattan using the OpenEO API. We'll use Sentinel-2 data to create a true-color RGB image of the Manhattan area.</p>"},{"location":"notebooks/manhattan/#connect-to-the-openeo-backend","title":"Connect to the OpenEO Backend\u00b6","text":"<p>We connect to the OpenEO backend service and authenticate using OpenID Connect. This establishes a connection to the remote processing service where our satellite data is stored.</p>"},{"location":"notebooks/manhattan/#define-spatial-extent","title":"Define Spatial Extent\u00b6","text":"<p>We define the geographic boundaries of our area of interest using longitude and latitude coordinates. This bounding box covers the Manhattan island area of New York City.</p>"},{"location":"notebooks/manhattan/#load-sentinel-2-data","title":"Load Sentinel-2 Data\u00b6","text":"<p>We load Sentinel-2 satellite imagery for our defined area using the <code>load_collection_and_reduce</code> process.</p> <ul> <li>We select the RGB bands (B04=Red, B03=Green, B02=Blue) for true-color visualization</li> <li>The temporal extent covers April to December 2022</li> <li>The \"first\" pixel selection method means we'll use the first available cloud-free pixel in the time range</li> </ul>"},{"location":"notebooks/manhattan/#scale-image-values","title":"Scale Image Values\u00b6","text":"<p>Raw satellite reflectance values need to be scaled to standard RGB display range (0-255). We define a processing function that:</p> <ol> <li>Scales the values from their original range (0-10000) to 0-255</li> <li>Applies truncation to ensure all values are valid integers within range</li> </ol>"},{"location":"notebooks/manhattan/#apply-processing-and-enhance-visual-appearance","title":"Apply Processing and Enhance Visual Appearance\u00b6","text":"<p>We apply the scaling function to our data cube, then use a color formula to enhance the visual appearance of the image. The color formula applies:</p> <ul> <li>Gamma correction (RGB 1.5) to adjust brightness and contrast</li> <li>Sigmoidal contrast enhancement (RGB 10 0.3) to improve detail visibility</li> <li>Saturation adjustment to enhance color vibrancy</li> </ul>"},{"location":"notebooks/manhattan/#save-and-display-result","title":"Save and Display Result\u00b6","text":"<p>Finally, we save the processed image as a PNG file and display it. This shows the true-color satellite view of Manhattan and surrounding areas.</p>"},{"location":"notebooks/manhattan/#conclusion","title":"Conclusion\u00b6","text":"<p>This notebook demonstrates how to use OpenEO to access, process, and visualize satellite imagery for urban areas. The workflow can be extended to include additional analysis, such as:</p> <ul> <li>Time series analysis to observe changes over multiple dates</li> <li>Land cover classification to identify different urban features</li> <li>Spectral indices to analyze vegetation, water, or built-up areas</li> <li>Image segmentation to extract specific features</li> </ul>"},{"location":"notebooks/ndvi_time_series/","title":"NDVI Time Series Analysis with OpenEO","text":"In\u00a0[1]: Copied! <pre>import json\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</pre> import json  import pandas as pd import matplotlib.pyplot as plt  In\u00a0[2]: Copied! <pre>import openeo\nconnection = openeo.connect(url=\"https://openeo.ds.io\").authenticate_oidc_authorization_code()\n</pre> import openeo connection = openeo.connect(url=\"https://openeo.ds.io\").authenticate_oidc_authorization_code() In\u00a0[3]: Copied! <pre>fields = json.loads(\n    \"\"\"{\n    \"type\": \"FeatureCollection\",\n    \"features\": [\n        {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.055945487931457, 51.222709834076504], [5.064972484168688, 51.221122565090525], [5.064972484168688, 51.221122565090525], [5.067474954083448, 51.218249806779134], [5.064827929485983, 51.21689628072789], [5.05917785594747, 51.217191909908095], [5.053553857094518, 51.21807492332223], [5.055945487931457, 51.222709834076504]]]}},\n        {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.063345886679116, 51.23087606640057], [5.06604742694687, 51.22886710731809], [5.070627820472246, 51.22874440121892], [5.068403609708207, 51.22657208381529], [5.064823257492447, 51.22676051738515], [5.064892324615199, 51.2283032878514], [5.063641745941974, 51.2285757299238], [5.062340811262595, 51.227722351687945], [5.06076005158084, 51.228042312276536], [5.063345886679116, 51.23087606640057]]]}},\n        {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.07163184674986, 51.23481147556147], [5.076706025697324, 51.23317590781036], [5.077828303041866, 51.233226237184724], [5.078024733866917, 51.23263978271262], [5.080771081607657, 51.23259097170763], [5.083734842574312, 51.23530464074437], [5.080957826735458, 51.23646091560258], [5.079752631651647, 51.23519531038643], [5.077238400183506, 51.23490534677628], [5.072856439300575, 51.23593546777778], [5.07163184674986, 51.23481147556147]]]}},\n        {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.083897244679042, 51.23510639883143], [5.081302408741335, 51.232922477780846], [5.082963802194108, 51.233146058575876], [5.084497702305552, 51.232672717580655], [5.085732850338428, 51.2340852086282], [5.083897244679042, 51.23510639883143]]]}}\n    ]}\n\"\"\"\n)\n</pre> fields = json.loads(     \"\"\"{     \"type\": \"FeatureCollection\",     \"features\": [         {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.055945487931457, 51.222709834076504], [5.064972484168688, 51.221122565090525], [5.064972484168688, 51.221122565090525], [5.067474954083448, 51.218249806779134], [5.064827929485983, 51.21689628072789], [5.05917785594747, 51.217191909908095], [5.053553857094518, 51.21807492332223], [5.055945487931457, 51.222709834076504]]]}},         {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.063345886679116, 51.23087606640057], [5.06604742694687, 51.22886710731809], [5.070627820472246, 51.22874440121892], [5.068403609708207, 51.22657208381529], [5.064823257492447, 51.22676051738515], [5.064892324615199, 51.2283032878514], [5.063641745941974, 51.2285757299238], [5.062340811262595, 51.227722351687945], [5.06076005158084, 51.228042312276536], [5.063345886679116, 51.23087606640057]]]}},         {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.07163184674986, 51.23481147556147], [5.076706025697324, 51.23317590781036], [5.077828303041866, 51.233226237184724], [5.078024733866917, 51.23263978271262], [5.080771081607657, 51.23259097170763], [5.083734842574312, 51.23530464074437], [5.080957826735458, 51.23646091560258], [5.079752631651647, 51.23519531038643], [5.077238400183506, 51.23490534677628], [5.072856439300575, 51.23593546777778], [5.07163184674986, 51.23481147556147]]]}},         {\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[5.083897244679042, 51.23510639883143], [5.081302408741335, 51.232922477780846], [5.082963802194108, 51.233146058575876], [5.084497702305552, 51.232672717580655], [5.085732850338428, 51.2340852086282], [5.083897244679042, 51.23510639883143]]]}}     ]} \"\"\" ) In\u00a0[4]: Copied! <pre>s2cube = connection.load_collection(\n    \"sentinel-2-l2a\",\n    temporal_extent=[\"2020-04-01\", \"2020-10-01\"],\n    spatial_extent={\"west\": 5.05, \"south\": 51.21, \"east\": 5.09, \"north\": 51.24},\n    bands=[\"B04_10m\", \"B08_10m\"],\n    max_cloud_cover=20,\n)\n\n# Extract individual bands\nred = s2cube.band(\"B04_10m\")\nnir = s2cube.band(\"B08_10m\")\n\n# Calculate NDVI using the formula: (NIR - Red) / (NIR + Red)\nndvi = (nir - red) / (nir + red)\n</pre> s2cube = connection.load_collection(     \"sentinel-2-l2a\",     temporal_extent=[\"2020-04-01\", \"2020-10-01\"],     spatial_extent={\"west\": 5.05, \"south\": 51.21, \"east\": 5.09, \"north\": 51.24},     bands=[\"B04_10m\", \"B08_10m\"],     max_cloud_cover=20, )  # Extract individual bands red = s2cube.band(\"B04_10m\") nir = s2cube.band(\"B08_10m\")  # Calculate NDVI using the formula: (NIR - Red) / (NIR + Red) ndvi = (nir - red) / (nir + red) <pre>/home/emathot/Workspace/DevelopmentSeed/titiler-openeo/.venv/lib/python3.10/site-packages/openeo/rest/connection.py:1140: UserWarning: sentinel-2-l2a property filtering with properties that are undefined in the collection metadata (summaries): eo:cloud_cover.\n  return DataCube.load_collection(\n</pre> In\u00a0[5]: Copied! <pre>timeseries = ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\")\n</pre> timeseries = ndvi.aggregate_spatial(geometries=fields, reducer=\"mean\") In\u00a0[6]: Copied! <pre>timeseries.download(\"timeseries-basic.csv\", format=\"csv\")\npd.read_csv(\"timeseries-basic.csv\", index_col=0).head()\n</pre> timeseries.download(\"timeseries-basic.csv\", format=\"csv\") pd.read_csv(\"timeseries-basic.csv\", index_col=0).head() Out[6]: feature_index value date 2020-09-22T10:46:49.025Z 0 0.426953 2020-09-19T10:36:49.024Z 0 0.423887 2020-09-17T10:50:31.024Z 0 0.420011 2020-09-14T10:40:31.024Z 0 0.395836 2020-09-12T10:46:29.024Z 0 0.376717 In\u00a0[7]: Copied! <pre>def plot_timeseries(filename, figsize=(6, 3)):\n    \"\"\"Plot NDVI time series from a CSV file\n\n    Parameters:\n    ----------\n    filename : str\n        Path to the CSV file containing time series data\n    figsize : tuple, optional\n        Figure size as (width, height) in inches\n    \"\"\"\n    df = pd.read_csv(filename, index_col=0)\n    df.index = pd.to_datetime(df.index)  # Convert index to datetime format\n\n    fig, ax = plt.subplots(figsize=figsize, dpi=90)\n    df.groupby(\"feature_index\")[\"value\"].plot(marker=\"o\", ax=ax)\n    ax.set_title(filename.split(\"/\")[-1])\n    ax.set_ylabel(\"NDVI\")\n    ax.set_ylim(0, 1)  # NDVI typically ranges from 0 to 1 for vegetation\n    ax.legend(title=\"parcel id\", loc=\"lower left\", ncol=2)\n\n\nplot_timeseries(\"timeseries-basic.csv\")\n</pre> def plot_timeseries(filename, figsize=(6, 3)):     \"\"\"Plot NDVI time series from a CSV file      Parameters:     ----------     filename : str         Path to the CSV file containing time series data     figsize : tuple, optional         Figure size as (width, height) in inches     \"\"\"     df = pd.read_csv(filename, index_col=0)     df.index = pd.to_datetime(df.index)  # Convert index to datetime format      fig, ax = plt.subplots(figsize=figsize, dpi=90)     df.groupby(\"feature_index\")[\"value\"].plot(marker=\"o\", ax=ax)     ax.set_title(filename.split(\"/\")[-1])     ax.set_ylabel(\"NDVI\")     ax.set_ylim(0, 1)  # NDVI typically ranges from 0 to 1 for vegetation     ax.legend(title=\"parcel id\", loc=\"lower left\", ncol=2)   plot_timeseries(\"timeseries-basic.csv\")"},{"location":"notebooks/ndvi_time_series/#ndvi-time-series-analysis-with-openeo","title":"NDVI Time Series Analysis with OpenEO\u00b6","text":"<p>This notebook demonstrates how to extract and analyze Normalized Difference Vegetation Index (NDVI) time series for agricultural parcels using Sentinel-2 imagery and the OpenEO API.</p>"},{"location":"notebooks/ndvi_time_series/#overview","title":"Overview\u00b6","text":"<p>In this notebook, we will:</p> <ol> <li>Connect to an OpenEO backend service</li> <li>Define agricultural field geometries</li> <li>Load Sentinel-2 imagery for a specific time period</li> <li>Calculate NDVI from red and near-infrared bands</li> <li>Extract time series data by aggregating NDVI values over field geometries</li> <li>Visualize and analyze the resulting time series</li> </ol>"},{"location":"notebooks/ndvi_time_series/#what-is-ndvi","title":"What is NDVI?\u00b6","text":"<p>The Normalized Difference Vegetation Index (NDVI) is a simple but effective index for quantifying vegetation greenness. It uses the contrast between the red and near-infrared reflectance of vegetation.</p> <p>NDVI is calculated as: (NIR - Red) / (NIR + Red)</p> <p>NDVI values range from -1 to 1:</p> <ul> <li>Values around 0 typically represent non-vegetated areas (water, bare soil, buildings)</li> <li>Values between 0.2 and 0.4 represent sparse vegetation</li> <li>Values between 0.4 and 0.8 represent dense vegetation (higher values indicate healthier vegetation)</li> </ul> <p>NDVI time series are valuable for monitoring crop growth, detecting anomalies, and analyzing seasonal patterns.</p>"},{"location":"notebooks/ndvi_time_series/#import-required-libraries","title":"Import Required Libraries\u00b6","text":"<p>We begin by importing the necessary Python libraries for data processing and visualization.</p>"},{"location":"notebooks/ndvi_time_series/#connect-to-openeo-backend","title":"Connect to OpenEO Backend\u00b6","text":"<p>Connect to a local OpenEO backend running on port 8081 and authenticate using OpenID Connect.</p>"},{"location":"notebooks/ndvi_time_series/#define-field-geometries","title":"Define Field Geometries\u00b6","text":"<p>Below we define four agricultural field geometries as GeoJSON Polygons. These fields will be used to extract NDVI time series. The coordinates are in WGS84 (EPSG:4326) and represent fields near latitude 51.22\u00b0 N, longitude 5.06\u00b0 E (likely in the Netherlands or Belgium).</p>"},{"location":"notebooks/ndvi_time_series/#load-sentinel-2-data-and-calculate-ndvi","title":"Load Sentinel-2 Data and Calculate NDVI\u00b6","text":"<p>Here we load Sentinel-2 L2A data for a 2-month period (June-August 2020) covering our area of interest. We select only the red (B04) and near-infrared (B08) bands at 10m resolution, as these are needed for NDVI calculation.</p> <p>The spatial extent is defined to cover all our field geometries with a small buffer.</p>"},{"location":"notebooks/ndvi_time_series/#extract-time-series-for-each-field","title":"Extract Time Series for Each Field\u00b6","text":"<p>Now we aggregate the NDVI values spatially for each field geometry using the mean as our reducer function. This gives us the average NDVI value within each field for each available date in our time period.</p> <p>The result is a time series of NDVI values for each field.</p>"},{"location":"notebooks/ndvi_time_series/#download-and-preview-time-series-data","title":"Download and Preview Time Series Data\u00b6","text":"<p>We download the time series data as a CSV file and preview the first few rows to understand its structure.</p>"},{"location":"notebooks/ndvi_time_series/#visualize-time-series","title":"Visualize Time Series\u00b6","text":"<p>This function helps us visualize the NDVI time series for all fields. The plot shows the temporal evolution of NDVI for each field, allowing us to compare vegetation growth patterns between fields.</p>"},{"location":"notebooks/ndvi_time_series/#conclusion","title":"Conclusion\u00b6","text":"<p>This notebook demonstrates a complete workflow for extracting and analyzing NDVI time series from Sentinel-2 imagery using OpenEO. The approach can be extended to:</p> <ul> <li>Analyze longer time periods to study seasonal patterns</li> <li>Include additional vegetation indices beyond NDVI</li> <li>Apply filtering or smoothing to handle noise in the time series</li> <li>Implement anomaly detection to identify unusual growth patterns</li> <li>Extract growth parameters such as start of season, peak of season, etc.</li> </ul> <p>NDVI time series analysis is valuable for a range of applications including crop monitoring, yield estimation, drought assessment, and phenological studies.</p>"},{"location":"notebooks/openeo/","title":"Openeo","text":"In\u00a0[2]: Copied! <pre>import openeo\n</pre> import openeo In\u00a0[4]: Copied! <pre>connection = openeo.connect(\"http://127.0.0.1:8080\")\nconnection\n</pre> connection = openeo.connect(\"http://127.0.0.1:8080\") connection Out[4]: <pre>&lt;Connection to 'http://127.0.0.1:8080/' with NullAuth&gt;</pre> In\u00a0[8]: Copied! <pre>collections = connection.list_collections()\ncollections\n</pre> collections = connection.list_collections() collections Out[8]: In\u00a0[\u00a0]: Copied! <pre>connection.describe_collection(collections[0][\"id\"])\n</pre> connection.describe_collection(collections[0][\"id\"]) Out[\u00a0]: In\u00a0[10]: Copied! <pre>connection.list_file_formats()\n</pre> connection.list_file_formats() Out[10]: In\u00a0[11]: Copied! <pre>connection.list_processes()\n</pre> connection.list_processes() Out[11]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}]}